{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0500d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../wofs_phi')\n",
    "import config as c\n",
    "import utilities\n",
    "from sklearn.metrics import brier_score_loss as BS\n",
    "import os\n",
    "from shutil import copy\n",
    "import time\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a77b713-e0bf-4b54-a12a-134633e9b5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class model_stats:\n",
    "    \n",
    "    def __init__(self, hazard, wofs_spinup_time, forecast_length, wofs_lead_time, train_radius, ver_radius, train_type, ver_type, model_type,\n",
    "                 n_folds, use_avg_srs, dates):\n",
    "        self.hazard = hazard\n",
    "        self.wofs_spinup_time = wofs_spinup_time\n",
    "        self.forecast_length = forecast_length\n",
    "        self.train_radius = train_radius\n",
    "        self.ver_radius = ver_radius\n",
    "        self.lead_time = wofs_lead_time\n",
    "        self.train_type = train_type\n",
    "        self.ver_type = ver_type\n",
    "        self.train_test_dir = '/work/ryan.martz/wofs_phi_data/%s_train/test_fcsts/%s' %(train_type, model_type)\n",
    "        self.ver_test_dir = '/work/ryan.martz/wofs_phi_data/%s_train/test_fcsts/%s' %(ver_type, model_type)\n",
    "        self.model_type = model_type\n",
    "        self.n_folds = n_folds\n",
    "        self.use_avg_srs = use_avg_srs\n",
    "        self.dates = dates\n",
    "    \n",
    "    def get_all_test_sr_events_fname_dir(self, fold):\n",
    "        start_min = self.lead_time\n",
    "        end_min = self.lead_time + self.forecast_length\n",
    "        train_save_dir = '%s/%s/wofslag_%s/length_%s/fold%s' %(self.train_test_dir, self.hazard, self.wofs_spinup_time, self.forecast_length, fold)\n",
    "        ver_save_dir = '%s/%s/wofslag_%s/length_%s/fold%s' %(self.ver_test_dir, self.hazard, self.wofs_spinup_time, self.forecast_length, fold)\n",
    "        if self.train_type == 'warnings':\n",
    "            if self.use_avg_srs:\n",
    "                all_srs_fname = '%s_%s_trained_all_rf_%s_avg_sr_probs_spinup%smin_length%smin_%s-%s_fold%s.npy' %(self.model_type, self.train_type, self.hazard,\n",
    "                                                                                                           self.wofs_spinup_time, self.forecast_length,\n",
    "                                                                                                           start_min, end_min, fold)\n",
    "            else:\n",
    "                all_srs_fname = '%s_%s_trained_all_rf_%s_sr_probs_spinup%smin_length%smin_%s-%s_fold%s.npy' %(self.model_type, self.train_type, self.hazard,\n",
    "                                                                                                           self.wofs_spinup_time, self.forecast_length,\n",
    "                                                                                                           start_min, end_min, fold)\n",
    "            all_probs_fname = '%s_%s_trained_all_rf_%s_raw_probs_spinup%smin_length%smin_%s-%s_fold%s.npy' %(self.model_type, self.train_type, self.hazard,\n",
    "                                                                                                       self.wofs_spinup_time, self.forecast_length,\n",
    "                                                                                                       start_min, end_min, fold)\n",
    "        else:\n",
    "            if self.use_avg_srs:\n",
    "                all_srs_fname = '%s_%s_trained_all_rf_%s_avg_sr_probs_spinup%smin_length%smin_%s-%s_r%skm_fold%s.npy' %(self.model_type, self.train_type, self.hazard,\n",
    "                                                                                                                 self.wofs_spinup_time,\n",
    "                                                                                                                 self.forecast_length, start_min, end_min,\n",
    "                                                                                                                 self.train_radius, fold)\n",
    "            else:\n",
    "                all_srs_fname = '%s_%s_trained_all_rf_%s_sr_probs_spinup%smin_length%smin_%s-%s_r%skm_fold%s.npy' %(self.model_type, self.train_type, self.hazard,\n",
    "                                                                                                                 self.wofs_spinup_time,\n",
    "                                                                                                                 self.forecast_length, start_min, end_min,\n",
    "                                                                                                                 self.train_radius, fold)\n",
    "            all_probs_fname = '%s_%s_trained_all_rf_%s_raw_probs_spinup%smin_length%smin_%s-%s_r%skm_fold%s.npy' %(self.model_type, self.train_type, self.hazard,\n",
    "                                                                                                       self.wofs_spinup_time, self.forecast_length,\n",
    "                                                                                                       start_min, end_min, self.train_radius, fold)\n",
    "        if self.ver_type == 'warnings':\n",
    "            all_events_fname = '%s_%s_trained_all_%s_events_spinup%smin_length%smin_%s-%s_fold%s.npy' %(self.model_type, self.ver_type, self.hazard, self.wofs_spinup_time,\n",
    "                                                                                                     self.forecast_length, start_min, end_min, fold)\n",
    "        else:\n",
    "            all_events_fname = '%s_%s_trained_all_%s_events_spinup%smin_length%smin_%s-%s_r%skm_fold%s.npy' %(self.model_type, self.ver_type, self.hazard,\n",
    "                                                                                                           self.wofs_spinup_time, self.forecast_length,\n",
    "                                                                                                           start_min, end_min, self.ver_radius, fold)\n",
    "        \n",
    "        return train_save_dir, ver_save_dir, all_srs_fname, all_probs_fname, all_events_fname\n",
    "    \n",
    "    def get_all_test_srs_probs_events_fold(self, fcst_dir, ver_dir, all_srs_fname, all_probs_fname, all_events_fname):\n",
    "        all_srs_fold = np.load('%s/%s' %(fcst_dir, all_srs_fname))\n",
    "        all_probs_fold = np.load('%s/%s' %(fcst_dir, all_probs_fname))\n",
    "        all_events_fold = np.load('%s/%s' %(ver_dir, all_events_fname))\n",
    "        return all_srs_fold, all_probs_fold, all_events_fold\n",
    "    \n",
    "    def get_all_test_srs_probs_events(self):\n",
    "        all_srs = []\n",
    "        all_probs = []\n",
    "        all_events = []\n",
    "        for fold in range(self.n_folds):\n",
    "            all_fcst_dir, all_ver_dir, all_srs_fname, all_probs_fname, all_events_fname = self.get_all_test_sr_events_fname_dir(fold)\n",
    "            print(all_srs_fname)\n",
    "            print(all_probs_fname)\n",
    "            print(all_events_fname)\n",
    "            all_srs_fold, all_probs_fold, all_events_fold = self.get_all_test_srs_probs_events_fold(all_fcst_dir, all_ver_dir, all_srs_fname, all_probs_fname, all_events_fname)\n",
    "            all_srs.extend(all_srs_fold)\n",
    "            all_probs.extend(all_probs_fold)\n",
    "            all_events.extend(all_events_fold)\n",
    "        return np.array(all_srs), np.array(all_probs), np.array(all_events)\n",
    "    \n",
    "    def calc_reliability(self, bins):\n",
    "        'bins should be given in decimal values'\n",
    "        \n",
    "        all_srs, all_probs, all_events = self.get_all_test_srs_probs_events()\n",
    "        print(len(all_srs), len(all_probs), len(all_events))\n",
    "        rel_sum_srs = 0\n",
    "        rel_sum_probs = 0\n",
    "        rel_climos_srs = []\n",
    "        rel_climos_probs = []\n",
    "        fcst_frequencies_srs = []\n",
    "        fcst_frequencies_probs = []\n",
    "        for i in range(len(bins)-1):\n",
    "            bin_start = bins[i]\n",
    "            bin_end = bins[i+1]\n",
    "            events_srs = all_events[np.where((all_srs >= bin_start) & (all_srs < bin_end))]\n",
    "            rel_srs = all_srs[np.where((all_srs >= bin_start) & (all_srs < bin_end))]\n",
    "            events_probs = all_events[np.where((all_probs >= bin_start) & (all_probs < bin_end))]\n",
    "            rel_probs = all_probs[np.where((all_probs >= bin_start) & (all_probs < bin_end))]\n",
    "            \n",
    "            if events_srs.size == 0:\n",
    "                rel_climos_srs.append(-1)\n",
    "            else:\n",
    "                rel_climos_srs.append(np.mean(events_srs))\n",
    "                rel_sum_srs += np.sum(np.power(rel_srs - events_srs, 2))\n",
    "            \n",
    "            if events_probs.size == 0:\n",
    "                rel_climos_probs.append(-1)\n",
    "            else:\n",
    "                rel_climos_probs.append(np.mean(events_probs))\n",
    "                rel_sum_probs += np.sum(np.power(rel_probs - events_probs, 2))\n",
    "            \n",
    "            fcst_frequencies_srs.append(rel_srs.size)\n",
    "            fcst_frequencies_probs.append(rel_probs.size)\n",
    "        \n",
    "        N = all_srs.size\n",
    "        rel_srs = rel_sum_srs/N\n",
    "        rel_probs = rel_sum_probs/N\n",
    "        \n",
    "        ver_climo = np.mean(all_events)\n",
    "        \n",
    "        return fcst_frequencies_srs, fcst_frequencies_probs, rel_srs, rel_probs, rel_climos_srs, rel_climos_probs, ver_climo\n",
    "    \n",
    "    def set_chunk_splits(self):\n",
    "        '''Does the k fold logic. The class stores a list of dates to train on, and this samples it into training, testing, validation for each fold.\n",
    "        This allows us to just use the fold number as an index to each of the lists to get the list of dates for the current fold for testing, validation,\n",
    "        and training.'''\n",
    "        \n",
    "        num_dates = len(self.dates)\n",
    "        indices = np.arange(num_dates)\n",
    "        splits = np.array_split(indices, self.n_folds)\n",
    "        chunk_splits = []\n",
    "        for i in range(len(splits)):\n",
    "            split = splits[i]\n",
    "            chunk_splits.append(split[0])\n",
    "        chunk_splits.append(num_dates)\n",
    "        self.date_test_folds = []\n",
    "        self.date_val_folds = []\n",
    "        self.date_train_folds = []\n",
    "        if self.n_folds == 1:\n",
    "            self.date_test_folds = [self.dates]\n",
    "            self.date_val_folds = [self.dates]\n",
    "            self.date_train_folds = [self.dates]\n",
    "            return\n",
    "        for i in range(self.n_folds):\n",
    "            if i == 0:\n",
    "                self.date_test_folds.append(self.dates[chunk_splits[i]:chunk_splits[i+1]])\n",
    "                self.date_val_folds.append(self.dates[chunk_splits[-2]:chunk_splits[-1]])\n",
    "                self.date_train_folds.append(self.dates[chunk_splits[i+1]:chunk_splits[i+1+(self.n_folds-2)]])\n",
    "            elif i == self.n_folds - 1:\n",
    "                self.date_test_folds.append(self.dates[chunk_splits[i]:chunk_splits[-1]])\n",
    "                self.date_val_folds.append(self.dates[chunk_splits[i-1]:chunk_splits[i]])\n",
    "                self.date_train_folds.append(self.dates[chunk_splits[0]:chunk_splits[self.n_folds-2]])\n",
    "            elif (i+1+(self.n_folds-2)) > (self.n_folds):\n",
    "                self.date_test_folds.append(self.dates[chunk_splits[i]:chunk_splits[i+1]])\n",
    "                self.date_val_folds.append(self.dates[chunk_splits[i-1]:chunk_splits[i]])\n",
    "                train_folds = self.dates[chunk_splits[i+1]:chunk_splits[-1]]\n",
    "                train_folds.extend(self.dates[chunk_splits[0]:chunk_splits[i-1]])\n",
    "                self.date_train_folds.append(train_folds)\n",
    "            else:\n",
    "                self.date_test_folds.append(self.dates[chunk_splits[i]:chunk_splits[i+1]])\n",
    "                self.date_val_folds.append(self.dates[chunk_splits[i-1]:chunk_splits[i]])\n",
    "                self.date_train_folds.append(self.dates[chunk_splits[i+1]:chunk_splits[i+1+(self.n_folds-2)]])\n",
    "        \n",
    "        return\n",
    "            \n",
    "    def calc_pod_sr(self, thresholds):\n",
    "        all_srs, all_probs, all_events = self.get_all_test_srs_probs_events()\n",
    "        pods_sr = []\n",
    "        pods_probs = []\n",
    "        srs_sr = []\n",
    "        srs_probs = []\n",
    "        thresholds_sr = []\n",
    "        thresholds_probs = []\n",
    "        for t in thresholds:\n",
    "            yes_fcst_events_srs = all_events[np.where(all_srs >= t)]\n",
    "            no_fcst_events_srs = all_events[np.where(all_srs < t)]\n",
    "            \n",
    "            a_srs = np.sum(yes_fcst_events_srs)\n",
    "            b_srs = yes_fcst_events_srs.size - a_srs\n",
    "            c_srs = np.sum(no_fcst_events_srs)\n",
    "            d_srs = no_fcst_events_srs.size - c_srs\n",
    "            \n",
    "            if (a_srs + c_srs > 0) and (a_srs + b_srs > 0):\n",
    "            \n",
    "                pod_srs = a_srs/(a_srs+c_srs)\n",
    "                sr_srs = a_srs/(a_srs+b_srs)\n",
    "\n",
    "                thresholds_sr.append(t)\n",
    "                srs_sr.append(sr_srs)\n",
    "                pods_sr.append(pod_srs)\n",
    "            \n",
    "            else:\n",
    "                thresholds_sr.append(-1)\n",
    "                srs_sr.append(-1)\n",
    "                pods_sr.append(-1)\n",
    "            \n",
    "            yes_fcst_events_probs = all_events[np.where(all_probs >= t)]\n",
    "            no_fcst_events_probs = all_events[np.where(all_probs < t)]\n",
    "            \n",
    "            a_probs = np.sum(yes_fcst_events_probs)\n",
    "            b_probs = yes_fcst_events_probs.size - a_probs\n",
    "            c_probs = np.sum(no_fcst_events_probs)\n",
    "            d_probs = no_fcst_events_probs.size - c_probs\n",
    "            \n",
    "            if (a_probs + c_probs > 0) and (a_probs + b_probs > 0):\n",
    "                pod_probs = a_probs/(a_probs+c_probs)\n",
    "                sr_probs = a_probs/(a_probs+b_probs)\n",
    "\n",
    "                thresholds_probs.append(t)\n",
    "                pods_probs.append(pod_probs)\n",
    "                srs_probs.append(sr_probs)\n",
    "            else:\n",
    "                thresholds_probs.append(-1)\n",
    "                pods_probs.append(-1)\n",
    "                srs_probs.append(-1)\n",
    "        \n",
    "        return thresholds_sr, pods_sr, srs_sr, thresholds_probs, pods_probs, srs_probs\n",
    "    \n",
    "    def gen_brier_skill_scores(self):\n",
    "        sr_skill_by_fold = []\n",
    "        probs_skill_by_fold = []\n",
    "        all_srs = []\n",
    "        all_probs = []\n",
    "        all_events = []\n",
    "        for fold in range(self.n_folds):\n",
    "            fcst_dir, ver_dir, all_srs_fname, all_probs_fname, all_events_fname = self.get_all_test_sr_events_fname_dir(fold)\n",
    "            all_srs_fold, all_probs_fold, all_events_fold = self.get_all_test_srs_probs_events_fold(fcst_dir, ver_dir, all_srs_fname, all_probs_fname, all_events_fname)\n",
    "            \n",
    "            #probs_less_10_indices = np.where(all_probs_fold < 0.1)\n",
    "            #all_probs_fold[probs_less_10_indices] = 0\n",
    "            #all_srs_fold[probs_less_10_indices] = 0\n",
    "            \n",
    "            num_fcsts = all_srs_fold.size\n",
    "            total_yes = np.sum(all_events_fold)\n",
    "            climo = total_yes/num_fcsts\n",
    "            climo_fcst_fold = np.ones(num_fcsts)*climo\n",
    "            \n",
    "            bs_sr_fold = BS(all_events_fold, all_srs_fold)\n",
    "            bs_probs_fold = BS(all_events_fold, all_probs_fold)\n",
    "            bs_climo_fold = BS(all_events_fold, climo_fcst_fold)\n",
    "            \n",
    "            bss_sr_fold = (bs_sr_fold - bs_climo_fold)/(-bs_climo_fold)\n",
    "            bss_probs_fold = (bs_probs_fold - bs_climo_fold)/(-bs_climo_fold)\n",
    "            \n",
    "            sr_skill_by_fold.append(bss_sr_fold)\n",
    "            probs_skill_by_fold.append(bss_probs_fold)\n",
    "            \n",
    "            all_srs.extend(all_srs_fold)\n",
    "            all_probs.extend(all_probs_fold)\n",
    "            all_events.extend(all_events_fold)\n",
    "            \n",
    "        num_fcsts = len(all_srs)\n",
    "        total_yes = np.sum(all_events)\n",
    "        climo = total_yes/num_fcsts\n",
    "        climo_fcst = np.ones(num_fcsts)*climo\n",
    "        \n",
    "        bs_sr = BS(all_events, all_srs)\n",
    "        bs_probs = BS(all_events, all_probs)\n",
    "        bs_climo = BS(all_events, climo_fcst)\n",
    "        \n",
    "        bss_sr = (bs_sr - bs_climo)/(-bs_climo)\n",
    "        bss_probs = (bs_probs - bs_climo)/(-bs_climo)\n",
    "        \n",
    "        return bss_sr, sr_skill_by_fold, bss_probs, probs_skill_by_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9679a1f3-fb35-4434-9c5a-42cd6ab90f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bss_fname_dir(home_dir, hazard, train_radius, ver_radius, forecast_length, train_type, ver_type, model_type, use_avg_srs = False):\n",
    "    if train_type == 'warnings' and ver_type == 'warnings':\n",
    "        save_dir = '%s/%s_trained/length_%s/%s' %(home_dir, train_type, forecast_length, hazard)\n",
    "        if use_avg_srs:\n",
    "            overall_sr_file = '%s_%s_trained_%s_verified_%s_%smin_bss_from_avg_sr_map_by_lead_time.npy' %(model_type, train_type, ver_type, hazard, forecast_length)\n",
    "            sr_by_fold_file = '%s_%s_trained_%s_verified_%s_%smin_bss_from_avg_sr_map_by_lead_time_and_fold.npy' %(model_type, train_type, ver_type, hazard, forecast_length)\n",
    "        else:\n",
    "            overall_sr_file = '%s_%s_trained_%s_verified_%s_%smin_bss_from_sr_map_by_lead_time.npy' %(model_type, train_type, ver_type, hazard, forecast_length)\n",
    "            sr_by_fold_file = '%s_%s_trained_%s_verified_%s_%smin_bss_from_sr_map_by_lead_time_and_fold.npy' %(model_type, train_type, ver_type, hazard, forecast_length)\n",
    "        \n",
    "        overall_probs_file = '%s_%s_trained_%s_verified_%s_%smin_bss_from_raw_probs_by_lead_time.npy' %(model_type, train_type, ver_type, hazard, forecast_length)\n",
    "        probs_by_fold_file = '%s_%s_trained_%s_verified_%s_%smin_bss_from_raw_probs_by_lead_time_and_fold.npy' %(model_type, train_type, ver_type, hazard, forecast_length)\n",
    "    \n",
    "    elif train_type == 'warnings':\n",
    "        save_dir = '%s/%s_trained/length_%s/%s' %(home_dir, train_type, forecast_length, hazard)\n",
    "        if use_avg_srs:\n",
    "            overall_sr_file = '%s_%s_trained_%s_%skm_verified_%s_%smin_bss_from_avg_sr_map_by_lead_time.npy' %(model_type, train_type, ver_type, ver_radius, hazard, forecast_length)\n",
    "            sr_by_fold_file = '%s_%s_trained_%s_%skm_verified_%s_%smin_%skm_bss_from_avg_sr_map_by_lead_time_and_fold.npy' %(model_type, train_type, ver_type, ver_radius, hazard, forecast_length)\n",
    "        else:\n",
    "            overall_sr_file = '%s_%s_trained_%s_%skm_verified_%s_%smin_bss_from_sr_map_by_lead_time.npy' %(model_type, train_type, ver_type, ver_radius, hazard, forecast_length)\n",
    "            sr_by_fold_file = '%s_%s_trained_%s_%skm_verified_%s_%smin_%skm_bss_from_sr_map_by_lead_time_and_fold.npy' %(model_type, train_type, ver_type, ver_radius, hazard, forecast_length)\n",
    "        \n",
    "        overall_probs_file = '%s_%s_trained_%s_%skm_verified_%s_%smin_%skm_bss_from_raw_probs_by_lead_time.npy' %(model_type, train_type, ver_type, ver_radius, hazard, forecast_length)\n",
    "        probs_by_fold_file = '%s_%s_trained_%s_%skm_verified_%s_%smin_%skm_bss_from_raw_probs_by_lead_time_and_fold.npy' %(model_type, train_type, ver_type, ver_radius, hazard, forecast_length)\n",
    "    \n",
    "    elif ver_type == 'warnings':\n",
    "        save_dir = '%s/%s_trained/length_%s/%s' %(home_dir, train_type, forecast_length, hazard)\n",
    "        if use_avg_srs:\n",
    "            overall_sr_file = '%s_%s_%skm_trained_%s_verified_%s_%smin_bss_from_avg_sr_map_by_lead_time.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "            sr_by_fold_file = '%s_%s_%skm_trained_%s_verified_%s_%smin_%skm_bss_from_avg_sr_map_by_lead_time_and_fold.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "        else:\n",
    "            overall_sr_file = '%s_%s_%skm_trained_%s_verified_%s_%smin_bss_from_sr_map_by_lead_time.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "            sr_by_fold_file = '%s_%s_%skm_trained_%s_verified_%s_%smin_%skm_bss_from_sr_map_by_lead_time_and_fold.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "        \n",
    "        overall_probs_file = '%s_%s_%skm_trained_%s_verified_%s_%smin_%skm_bss_from_raw_probs_by_lead_time.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "        probs_by_fold_file = '%s_%s_%skm_trained_%s_verified_%s_%smin_%skm_bss_from_raw_probs_by_lead_time_and_fold.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "    \n",
    "    else:\n",
    "        save_dir = '%s/%s_trained/length_%s/%s' %(home_dir, train_type, forecast_length, hazard)\n",
    "        if use_avg_srs:\n",
    "            overall_sr_file = '%s_%s_%skm_trained_%s_%skm_verified_%s_%smin_bss_from_avg_sr_map_by_lead_time.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "            sr_by_fold_file = '%s_%s_%skm_trained_%s_%skm_verified_%s_%smin_bss_from_avg_sr_map_by_lead_time_and_fold.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "        else:\n",
    "            overall_sr_file = '%s_%s_%skm_trained_%s_%skm_verified_%s_%smin_bss_from_sr_map_by_lead_time.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "            sr_by_fold_file = '%s_%s_%skm_trained_%s_%skm_verified_%s_%smin_bss_from_sr_map_by_lead_time_and_fold.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "        \n",
    "        overall_probs_file = '%s_%s_%skm_trained_%s_%skm_verified_%s_%smin_bss_from_raw_probs_by_lead_time.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "        probs_by_fold_file = '%s_%s_%skm_trained_%s_%skm_verified_%s_%smin_bss_from_raw_probs_by_lead_time_and_fold.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length)\n",
    "    \n",
    "    return save_dir, overall_sr_file, overall_probs_file, sr_by_fold_file, probs_by_fold_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa12776-2dda-48ef-aa96-1be0486fabb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bss_start_i(home_dir, hazard, train_radius, ver_radius, forecast_length, train_type, ver_type, model_type, use_avg_srs = False):\n",
    "    \n",
    "    save_dir, overall_sr_file, overall_probs_file, sr_by_fold_file, probs_by_fold_file = get_bss_fname_dir(home_dir, hazard, train_radius, ver_radius, forecast_length, train_type, ver_type, model_type, use_avg_srs = use_avg_srs)\n",
    "    \n",
    "    if not (os.path.isfile('%s/%s' %(save_dir, overall_sr_file)) and os.path.isfile('%s/%s' %(save_dir, overall_probs_file)) and os.path.isfile('%s/%s' %(save_dir, sr_by_fold_file)) and os.path.isfile('%s/%s' %(save_dir, probs_by_fold_file))):\n",
    "        return 0\n",
    "    \n",
    "    npy = np.load('%s/%s' %(save_dir, overall_sr_file))\n",
    "    return npy.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "949a5836-1f48-475b-8835-6d90653f4f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_done_skills(home_dir, hazard, train_radius, ver_radius, forecast_length, train_type, ver_type, model_type, use_avg_srs = False):\n",
    "    \n",
    "    save_dir, overall_sr_file, overall_probs_file, sr_by_fold_file, probs_by_fold_file = get_bss_fname_dir(home_dir, hazard, train_radius, ver_radius, forecast_length, train_type, ver_type, model_type, use_avg_srs = use_avg_srs)\n",
    "    \n",
    "    overall_srs = np.load('%s/%s' %(save_dir, overall_sr_file))\n",
    "    overall_probs = np.load('%s/%s' %(save_dir, overall_probs_file))\n",
    "    sr_by_fold = np.load('%s/%s' %(save_dir, sr_by_fold_file))\n",
    "    probs_by_fold = np.load('%s/%s' %(save_dir, probs_by_fold_file))\n",
    "    \n",
    "    return overall_srs, overall_probs, sr_by_fold, probs_by_fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03657a2b-a5ef-49bc-afae-a97a784123a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "home_dir = '/work/ryan.martz/wofs_phi_data/experiments'\n",
    "########################## Calc BSS ##########################\n",
    "\n",
    "num_folds = 5\n",
    "hazards = ['hail', 'wind', 'tornado']\n",
    "radii = [39]\n",
    "wofs_spinup_time = 25\n",
    "forecast_length = 60\n",
    "leads = [30, 60, 90, 120, 150, 180]\n",
    "train_types = ['obs', 'obs_and_warnings']\n",
    "model_type = 'wofs_psv2_no_torp'\n",
    "use_avg_srs = True\n",
    "for train_type in train_types:\n",
    "    ver_type = train_type\n",
    "    for hazard in hazards:\n",
    "        for train_radius in radii:\n",
    "            ver_radius = train_radius\n",
    "            sr_skill_by_lead = np.zeros(len(leads))\n",
    "            probs_skill_by_lead = np.zeros(len(leads))\n",
    "            sr_skill_by_lead_fold = np.zeros((len(leads), num_folds))\n",
    "            probs_skill_by_lead_fold = np.zeros((len(leads), num_folds))\n",
    "            #start_i = get_bss_start_i(home_dir, hazard, train_radius, ver_radius, forecast_length, train_type, ver_type, model_type, use_avg_srs = use_avg_srs)\n",
    "            start_i = 0\n",
    "            if not (start_i == 0):\n",
    "                sr_skill_by_lead[0:start_i], probs_skill_by_lead[0:start_i], sr_skill_by_lead_fold[0:start_i,:], probs_skill_by_lead_fold[0:start_i,:] = get_done_skills(home_dir, hazard, train_radius, ver_radius, forecast_length, train_type, ver_type, model_type, use_avg_srs = use_avg_srs)\n",
    "            for i in range(start_i, len(leads)):\n",
    "                lead = leads[i]\n",
    "                m = model_stats(hazard, wofs_spinup_time, forecast_length, lead, train_radius, ver_radius, train_type, ver_type, model_type, num_folds, use_avg_srs)\n",
    "                bss_sr, sr_skill_by_fold, bss_probs, probs_skill_by_fold = m.gen_brier_skill_scores()\n",
    "                sr_skill_by_lead_fold[i,:] = sr_skill_by_fold\n",
    "                probs_skill_by_lead_fold[i,:] = probs_skill_by_fold\n",
    "                sr_skill_by_lead[i] = bss_sr\n",
    "                probs_skill_by_lead[i] = bss_probs\n",
    "\n",
    "            save_dir, overall_sr_file, overall_probs_file, sr_by_fold_file, probs_by_fold_file = get_bss_fname_dir(home_dir, hazard, train_radius, ver_radius, forecast_length, train_type, ver_type, model_type, use_avg_srs = use_avg_srs)\n",
    "\n",
    "            utilities.save_data(save_dir, overall_sr_file, sr_skill_by_lead, 'npy')\n",
    "            utilities.save_data(save_dir, overall_probs_file, probs_skill_by_lead, 'npy')\n",
    "            utilities.save_data(save_dir, sr_by_fold_file, sr_skill_by_lead_fold, 'npy')\n",
    "            utilities.save_data(save_dir, probs_by_fold_file, probs_skill_by_lead_fold, 'npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "954246c4-03e3-4f21-b89f-9706b9c27d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 128880000 is out of bounds for axis 0 with size 128880000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     31\u001b[0m bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m fcst_frequencies_srs, fcst_frequencies_probs, rel_srs, rel_probs, rel_climos_srs, rel_climos_probs, ver_climo \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_reliability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m rel_summary_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m6\u001b[39m, points\u001b[38;5;241m.\u001b[39msize))\n\u001b[1;32m     34\u001b[0m rel_summary_data[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m rel_srs\n",
      "Cell \u001b[0;32mIn[2], line 90\u001b[0m, in \u001b[0;36mmodel_stats.calc_reliability\u001b[0;34m(self, bins)\u001b[0m\n\u001b[1;32m     88\u001b[0m bin_start \u001b[38;5;241m=\u001b[39m bins[i]\n\u001b[1;32m     89\u001b[0m bin_end \u001b[38;5;241m=\u001b[39m bins[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 90\u001b[0m events_srs \u001b[38;5;241m=\u001b[39m \u001b[43mall_events\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_srs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbin_start\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_srs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbin_end\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     91\u001b[0m rel_srs \u001b[38;5;241m=\u001b[39m all_srs[np\u001b[38;5;241m.\u001b[39mwhere((all_srs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m bin_start) \u001b[38;5;241m&\u001b[39m (all_srs \u001b[38;5;241m<\u001b[39m bin_end))]\n\u001b[1;32m     92\u001b[0m events_probs \u001b[38;5;241m=\u001b[39m all_events[np\u001b[38;5;241m.\u001b[39mwhere((all_probs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m bin_start) \u001b[38;5;241m&\u001b[39m (all_probs \u001b[38;5;241m<\u001b[39m bin_end))]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 128880000 is out of bounds for axis 0 with size 128880000"
     ]
    }
   ],
   "source": [
    "home_dir = '/work/ryan.martz/wofs_phi_data/experiments'\n",
    "########################## Calc Reliability ##########################\n",
    "'''Documentation on Reliability Summary Files (Content by Row):\n",
    "1. Reliability Score from SR forecasts, Reliability Score from raw prob forecasts, Overall climo of forecasted event, 0s the rest of the row\n",
    "2. The point forecasts to use for plotting (ex: 0.05, 0.15, 0.25, etc. for 0-0.1, 0.1-0.2, 0.2-0.3, etc.\n",
    "3. The frequency of forecasts in each range for SR probs\n",
    "4. The event climatology given such a forecast from the SRs\n",
    "5. The frequency of forecasts in each range for raw probs\n",
    "6. The event climatology given such a forecast from the raw probs'''\n",
    "\n",
    "num_folds = 5\n",
    "hazards = ['tornado', 'hail', 'wind']\n",
    "radii = [39]\n",
    "wofs_spinup_time = 25\n",
    "forecast_length = 60\n",
    "leads = [30, 60, 90, 120, 150, 180]\n",
    "train_types = ['obs_and_warnings', 'obs']\n",
    "ver_types = ['obs_and_warnings', 'obs']\n",
    "model_type = 'wofs_psv2_no_torp'\n",
    "use_avg_srs = True\n",
    "\n",
    "for train_type in train_types:\n",
    "    for ver_type in ver_types:\n",
    "        for hazard in hazards:\n",
    "            for train_radius in radii:\n",
    "                ver_radius = train_radius\n",
    "                for i in range(len(leads)):\n",
    "                    lead = leads[i]\n",
    "                    m = model_stats(hazard, wofs_spinup_time, forecast_length, lead, train_radius, ver_radius, train_type, ver_type, model_type, num_folds, use_avg_srs)\n",
    "                    points = np.arange(0.05, 1, 0.1)\n",
    "                    bins = np.arange(0, 1.01, 0.1)\n",
    "                    fcst_frequencies_srs, fcst_frequencies_probs, rel_srs, rel_probs, rel_climos_srs, rel_climos_probs, ver_climo = m.calc_reliability(bins)\n",
    "                    rel_summary_data = np.zeros((6, points.size))\n",
    "                    rel_summary_data[0,0] = rel_srs\n",
    "                    rel_summary_data[0,1] = rel_probs\n",
    "                    rel_summary_data[0,2] = ver_climo\n",
    "                    rel_summary_data[1,:] = points\n",
    "                    rel_summary_data[2,:] = fcst_frequencies_srs\n",
    "                    rel_summary_data[3,:] = rel_climos_srs\n",
    "                    rel_summary_data[4,:] = fcst_frequencies_probs\n",
    "                    rel_summary_data[5,:] = rel_climos_probs\n",
    "                    save_dir = '%s/%s_trained/length_%s/%s' %(home_dir, train_type, forecast_length, hazard)\n",
    "                    if train_type == 'warnings' and ver_type == 'warnings':\n",
    "                        if use_avg_srs:\n",
    "                            rel_fname = '%s_%s_trained_%s_verified_%s_%smin_reliability_data_avg_srs_%s-%s.npy' %(model_type, train_type, ver_type, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                        else:\n",
    "                            rel_fname = '%s_%s_trained_%s_verified_%s_%smin_reliability_data_%s-%s.npy' %(model_type, train_type, ver_type, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                    elif train_type == 'warnings':\n",
    "                        if use_avg_srs:\n",
    "                            rel_fname = '%s_%s_trained_%s_%skm_verified_%s_%smin_reliability_data_avg_srs_%s-%s.npy' %(model_type, train_type, ver_type, ver_radius, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                        else:\n",
    "                            rel_fname = '%s_%s_trained_%s_%skm_verified_%s_%smin_reliability_data_%s-%s.npy' %(model_type, train_type, ver_type, ver_radius, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                    elif ver_type == 'warnings':\n",
    "                        if use_avg_srs:\n",
    "                            rel_fname = '%s_%s_%skm_trained_%s_verified_%s_%smin_reliability_data_avg_srs_%s-%s.npy' %(model_type, train_type, train_radius, ver_type, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                        else:\n",
    "                            rel_fname = '%s_%s_%skm_trained_%s_verified_%s_%smin_reliability_data_%s-%s.npy' %(model_type, train_type, train_radius, ver_type, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                    else:\n",
    "                        if use_avg_srs:\n",
    "                            rel_fname = '%s_%s_%skm_trained_%s_%skm_verified_%s_%smin_reliability_data_avg_srs_%s-%s.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                        else:\n",
    "                            rel_fname = '%s_%s_%skm_trained_%s_%skm_verified_%s_%smin_reliability_data_%s-%s.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                    utilities.save_data(save_dir, rel_fname, rel_summary_data, 'npy')\n",
    "                    time.sleep(2)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167eb57a-fbea-4276-a761-a5dec247b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/work/ryan.martz/wofs_phi_data/experiments'\n",
    "########################## Calc Performance Diagram Stats ##########################\n",
    "'''Performance Diagram Summary Data Files by Row:\n",
    "1. Forecast Thresholds for SR data\n",
    "2. POD using SR probs\n",
    "3. SR using SR probs\n",
    "4. Forecast Thresholds for raw probs\n",
    "5. POD using raw probs\n",
    "6. SR using raw probs'''\n",
    "\n",
    "num_folds = 5\n",
    "hazards = ['tornado', 'hail', 'wind']\n",
    "radii = [39]\n",
    "wofs_spinup_time = 25\n",
    "forecast_length = 60\n",
    "leads = [30, 60, 90, 120, 150, 180]\n",
    "train_types = ['obs_and_warnings', 'obs']\n",
    "ver_types = ['obs_and_warnings', 'obs']\n",
    "model_type = 'wofs_psv2_no_torp'\n",
    "use_avg_srs = True\n",
    "\n",
    "for train_type in train_types:\n",
    "    for ver_type in ver_types:\n",
    "        for hazard in hazards:\n",
    "            for train_radius in radii:\n",
    "                ver_radius = train_radius\n",
    "                for i in range(len(leads)):\n",
    "                    lead = leads[i]\n",
    "                    m = model_stats(hazard, wofs_spinup_time, forecast_length, lead, train_radius, ver_radius, train_type, ver_type, model_type, num_folds, use_avg_srs)\n",
    "                    if hazard == 'tornado':\n",
    "                        thresholds = np.array([0, 0.02, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "                    else:\n",
    "                        thresholds = np.arange(0, 1.01, 0.1)\n",
    "                    thresholds_sr, pods_sr, srs_sr, thresholds_probs, pods_probs, srs_probs = m.calc_pod_sr(thresholds)\n",
    "                    pd_summary_data = np.zeros((6, thresholds.size))\n",
    "                    pd_summary_data[0,:] = thresholds_sr\n",
    "                    pd_summary_data[1,:] = pods_sr\n",
    "                    pd_summary_data[2,:] = srs_sr\n",
    "                    pd_summary_data[3,:] = thresholds_probs\n",
    "                    pd_summary_data[4,:] = pods_probs\n",
    "                    pd_summary_data[5,:] = srs_probs\n",
    "                    \n",
    "                    save_dir = '%s/%s_trained/length_%s/%s' %(home_dir, train_type, forecast_length, hazard)\n",
    "                    if train_type == 'warnings' and ver_type == 'warnings':\n",
    "                        if use_avg_srs:\n",
    "                            pd_fname = '%s_%s_trained_%s_verified_%s_%smin_performance_diagram_data_avg_srs_%s-%s.npy' %(model_type, train_type, ver_type, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                        else:\n",
    "                            pd_fname = '%s_%s_trained_%s_verified_%s_%smin_performance_diagram_data_%s-%s.npy' %(model_type, train_type, ver_type, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                    elif train_type == 'warnings':\n",
    "                        if use_avg_srs:\n",
    "                            pd_fname = '%s_%s_trained_%s_%skm_verified_%s_%smin_performance_diagram_data_avg_srs_%s-%s.npy' %(model_type, train_type, ver_type, ver_radius, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                        else:\n",
    "                            pd_fname = '%s_%s_trained_%s_%skm_verified_%s_%smin_performance_diagram_data_%s-%s.npy' %(model_type, train_type, ver_type, ver_radius, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                    elif ver_type == 'warnings':\n",
    "                        if use_avg_srs:\n",
    "                            pd_fname = '%s_%s_%skm_trained_%s_verified_%s_%smin_performance_diagram_data_avg_srs_%s-%s.npy' %(model_type, train_type, train_radius, ver_type, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                        else:\n",
    "                            pd_fname = '%s_%s_%skm_trained_%s_verified_%s_%smin_performance_diagram_data_%s-%s.npy' %(model_type, train_type, train_radius, ver_type, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                    else:\n",
    "                        if use_avg_srs:\n",
    "                            pd_fname = '%s_%s_%skm_trained_%s_%skm_verified_%s_%smin_performance_diagram_data_avg_srs_%s-%s.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                        else:\n",
    "                            pd_fname = '%s_%s_%skm_trained_%s_%skm_verified_%s_%smin_performance_diagram_data_%s-%s.npy' %(model_type, train_type, train_radius, ver_type, ver_radius, hazard, forecast_length, lead, lead+forecast_length)\n",
    "                    \n",
    "                    utilities.save_data(save_dir, pd_fname, pd_summary_data, 'npy')\n",
    "                    \n",
    "                    time.sleep(2)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6052c97-cc59-446b-bb50-78268393592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Transfer Ideal Models ##########################\n",
    "\n",
    "home_dir = '/work/ryan.martz/wofs_phi_data/experiments'\n",
    "sr_paste_dir = '/work/eric.loken/wofs/2024_update/SFE2024/sr_csv/latest'\n",
    "model_paste_dir = '/work/eric.loken/wofs/2024_update/SFE2024/rf_models/latest'\n",
    "model_type = 'wofs_psv2_no_torp'\n",
    "hazards = ['hail', 'wind', 'tornado']\n",
    "train_radii = [39]\n",
    "wofs_lag = 25\n",
    "length = 60\n",
    "leads = [30, 60, 90, 120, 150, 180]\n",
    "train_types = ['obs_and_warnings', 'obs']\n",
    "use_avg_srs = True\n",
    "for train_type in train_types:\n",
    "    ver_type = train_type\n",
    "    validation_dir = '/work/ryan.martz/wofs_phi_data/%s_train/validation_fcsts/%s' %(train_type, model_type)\n",
    "    train_dir = '/work/ryan.martz/wofs_phi_data/%s_train/models/%s' %(train_type, model_type)\n",
    "    for haz in hazards:\n",
    "        for train_r in train_radii:\n",
    "            ver_r = train_r\n",
    "            for j in range(len(leads)):\n",
    "                lead = leads[j]\n",
    "                \n",
    "                sr_skills_dir, __, __, sr_skills_fname, __ = get_bss_fname_dir(home_dir, haz, train_r, ver_r, length, train_type, ver_type, model_type, use_avg_srs = use_avg_srs)\n",
    "                sr_skill_by_lead_time_fold = np.load('%s/%s' %(sr_skills_dir, sr_skills_fname))\n",
    "                \n",
    "                for i in range(len(sr_skill_by_lead_time_fold[:,0])):\n",
    "                    ideal_fold = np.where(sr_skill_by_lead_time_fold[i,:] == max(sr_skill_by_lead_time_fold[i,:]))[0][0]\n",
    "                    \n",
    "                    if use_avg_srs:\n",
    "                        sr_dir = '%s/%s/wofslag_%s/length_%s' %(validation_dir, haz, wofs_lag, length)\n",
    "                    else:\n",
    "                        sr_dir = '%s/%s/wofslag_%s/length_%s/all_raw_probs_fold%s' %(validation_dir, haz, wofs_lag, length, ideal_fold)\n",
    "                    \n",
    "                    model_dir = '%s/%s/wofslag_%s/length_%s' %(train_dir, haz, wofs_lag, length)\n",
    "                    if train_type == 'warnings':\n",
    "                        if use_avg_srs:\n",
    "                            sr_fname = '%s_%s_trained_avg_sr_map_%s_spinup%smin_length%smin_%s-%s.csv' %(model_type, train_type, haz, wofs_lag, length, lead, lead+length)\n",
    "                        else:\n",
    "                            sr_fname = '%s_%s_trained_sr_map_%s_spinup%smin_length%smin_%s-%s_fold%s.csv' %(model_type, train_type, haz, wofs_lag, length, lead, lead+length, ideal_fold)\n",
    "                        \n",
    "                        sr_paste_name = '%s_%s-%smin_%s_sr_map.csv' %(train_type, lead, lead+length, haz)\n",
    "                        model_fname = '%s_%s_trained_wofsphi_%s_%smin_window%s-%s_fold%s.pkl' %(model_type, train_type, haz, length, lead, lead+length, ideal_fold)\n",
    "                        model_paste_fname = '%s_trained_wofsphi_%s_%smin_window%s-%s.pkl' %(train_type, haz, length, lead, lead+length)\n",
    "                    else:\n",
    "                        if use_avg_srs:\n",
    "                            sr_fname = '%s_%s_trained_avg_sr_map_%s_spinup%smin_length%smin_%s-%s_r%skm.csv' %(model_type, train_type, haz, wofs_lag, length, lead, lead+length, r)\n",
    "                        else:\n",
    "                            sr_fname = '%s_%s_trained_sr_map_%s_spinup%smin_length%smin_%s-%s_r%skm_fold%s.csv' %(model_type, train_type, haz, wofs_lag, length, lead, lead+length, r, ideal_fold)\n",
    "                        sr_paste_name = '%s_%skm_%s-%smin_%s_sr_map.csv' %(train_type, r, lead, lead+length, haz)\n",
    "                        model_fname = '%s_%s_trained_wofsphi_%s_%smin_window%s-%s_r%skm_fold%s.pkl' %(model_type, train_type, haz, length, lead, lead+length, r, ideal_fold)\n",
    "                        model_paste_fname = '%s_trained_wofsphi_%s_%smin_window%s-%s_r%skm.pkl' %(train_type, haz, length, lead, lead+length, r)\n",
    "                    \n",
    "                    full_sr_fname = '%s/%s' %(sr_dir, sr_fname)\n",
    "                    full_model_fname = '%s/%s' %(model_dir, model_fname)\n",
    "                    \n",
    "                    \n",
    "                    copy(full_sr_fname, '%s/%s' %(sr_paste_dir, sr_paste_name))\n",
    "                    copy(full_model_fname, '%s/%s' %(model_paste_dir, model_paste_fname))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "387c9daf-a8ea-48ad-8f30-8296b97e5080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_dir = '/work/ryan.martz/wofs_phi_data/experiments'\n",
    "train_types = ['obs', 'obs_and_warnings']\n",
    "hazards = ['hail', 'wind', 'tornado']\n",
    "length = 60\n",
    "#### rename bss files:\n",
    "for train_type in train_types:\n",
    "    bss_dir = '%s/%s_trained' %(top_dir, train_type)\n",
    "    for hazard in hazards:\n",
    "        haz_dir = '%s/length_%s/%s' %(bss_dir, length, hazard)\n",
    "        for file in os.listdir(haz_dir):\n",
    "            if '_bss_' in file:\n",
    "                splits = file.split('_')\n",
    "                if 'and_fold' in file:\n",
    "                    r_split = splits[-10]\n",
    "                else:\n",
    "                    r_split = splits[-8]\n",
    "                new_fname1 = file[0:file.find(r_split)] + file[file.find(r_split)+len(r_split)+1:]\n",
    "                new_fname2 = new_fname1[0:new_fname1.find('trained')] + r_split + '_' + new_fname1[new_fname1.find('trained'):]\n",
    "                new_fname3 = new_fname2[0:new_fname2.find('verified')] + r_split + '_' + new_fname2[new_fname2.find('verified'):]\n",
    "                os.rename('%s/%s' %(haz_dir, file), '%s/%s' %(haz_dir, new_fname3))\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a062761-53b5-4ed1-afc2-f7d28ed9b1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '30km'\n",
    "a[0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b93d4265-d835-426e-8926-6cfbfde41207",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wofs_psv2_no_torp_obs_trained_obs_verified_hail_60min_7.5km_bss_from_raw_probs_by_lead_time_and_fold.npy'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b6a7ab6-df7c-42d3-8b0c-ee539a818704",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wofs_psv2_no_torp_obs_obs_verified_hail_60min_7.5km_bss_from_raw_probs_by_lead_time_and_fold.npy'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[0:file.find('trained')] + file[file.find('trained')+len('trained')+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "761efa35-5f57-40c5-b66d-f6745f889171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wofs_psv2_no_torp_obs_7.5km_trained_obs_verified_hail_60min_7.5km_bss_from_raw_probs_by_lead_time_and_fold.npy'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[0:file.find('trained')] + r_split + '_' + file[file.find('trained'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834fa29-2d45-41a5-9427-1ce340bbcecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
